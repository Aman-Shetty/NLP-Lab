{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce26963a-1194-4cf5-8833-4cda3c54686a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sahyadri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sahyadri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5d092f-5146-43fd-989e-3e34dc58796f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two relevant documents for the query document with the content 'Rama watching the rain': \n",
      "\n",
      "Euclidean Distance: ['Today Rama is not going outside to watch rain', 'It is going to rain today']\n",
      "\n",
      "Cosine Similarity: ['Today Rama is not going outside to watch rain', 'It is going to rain today']\n",
      "\n",
      "Jaccard Similarity: ['Today Rama is not going outside to watch rain', 'Tomorrow Rama is going to watch the rain at sea shore']\n",
      "\n",
      "Dice Similarity Coefficient: ['Today Rama is not going outside to watch rain', 'Tomorrow Rama is going to watch the rain at sea shore']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(doc):\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    filtered_tokens = [w for w in tokens if w.isalnum() and w not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "documents = [\n",
    "    \"It is going to rain today\",\n",
    "    \"Today Rama is not going outside to watch rain\",\n",
    "    \"I am going to watch the movie tomorrow with Rama\",\n",
    "    \"Tomorrow Rama is going to watch the rain at sea shore\"\n",
    "]\n",
    "\n",
    "query = \"Rama watching the rain\"\n",
    "\n",
    "preprocessed_docs = [preprocess(doc) for doc in documents]\n",
    "preprocessed_query = preprocess(query)\n",
    "\n",
    "# Create term-document matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_docs + [preprocessed_query])\n",
    "\n",
    "# Apply LSA\n",
    "lsa = TruncatedSVD(n_components=2)\n",
    "X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "# Separate the query vector\n",
    "query_vec_lsa = X_lsa[-1]\n",
    "doc_vecs_lsa = X_lsa[:-1]\n",
    "\n",
    "# Similarity Measures\n",
    "euclidean = euclidean_distances(doc_vecs_lsa, query_vec_lsa.reshape(1, -1)).flatten()\n",
    "cosine = cosine_similarity(doc_vecs_lsa, query_vec_lsa.reshape(1, -1)).flatten()\n",
    "cosine = 1 - cosine  # Invert cosine similarity to treat it as a distance\n",
    "\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    set1, set2 = set(doc1.split()), set(doc2.split())\n",
    "    return 1 - len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def dice_similarity(doc1, doc2):\n",
    "    set1, set2 = set(doc1.split()), set(doc2.split())\n",
    "    return 1 - (2 * len(set1 & set2)) / (len(set1) + len(set2))\n",
    "\n",
    "jaccard = np.array([jaccard_similarity(preprocessed_query, doc) for doc in preprocessed_docs])\n",
    "dice = np.array([dice_similarity(preprocessed_query, doc) for doc in preprocessed_docs])\n",
    "\n",
    "# Find the top 2 relevant documents\n",
    "def top_k_documents(similarity, k=2):\n",
    "    return np.argsort(similarity)[:k]\n",
    "\n",
    "top_k_euclidean = top_k_documents(euclidean)\n",
    "top_k_cosine = top_k_documents(cosine)\n",
    "top_k_jaccard = top_k_documents(jaccard)\n",
    "top_k_dice = top_k_documents(dice)\n",
    "\n",
    "# Output the most relevant documents\n",
    "results = {\n",
    "    \"Euclidean Distance\": top_k_euclidean,\n",
    "    \"Cosine Similarity\": top_k_cosine,\n",
    "    \"Jaccard Similarity\": top_k_jaccard,\n",
    "    \"Dice Similarity Coefficient\": top_k_dice\n",
    "}\n",
    "print(\"Top two relevant documents for the query document with the content 'Rama watching the rain': \\n\")\n",
    "for measure, indices in results.items():\n",
    "    print(f\"{measure}: {[documents[i] for i in indices]}\"+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
